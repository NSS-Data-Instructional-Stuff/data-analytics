{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pandas `.concat( )`  method is used to concatenate two dataframes based on shared column names\n",
    "- we will create two dataframes and then concatenate them\n",
    "- this would be useful if you had, for example, two different years of data with the same columns that you want to explore together; in a case like this, you would want to add a year column before joining them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2023 = { 'state' : ['NY','WV','TN'],\n",
    "         'count' : [14,55,63],\n",
    "         'code' : ['ab65','88ui','u7r4']}\n",
    "data_2024 = { 'state' : ['NY','WV','TN'],\n",
    "         'count' : [7,78,29],\n",
    "         'code' : ['0o09','jj33','1d6u']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023 = pd.DataFrame(data_2023)\n",
    "df_2024 = pd.DataFrame(data_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before we concatenate `df_2023` and `df_2024` we need to add a column for the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023['year'] = '2023'\n",
    "df_2024['year'] = '2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data = pd.concat([df_2023, df_2024])\n",
    "concat_data\n",
    "\n",
    "## Notice that the index repeats itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `reset_index( )` method will change these to a 0-based incrementing index\n",
    "- add the `drop = True` argument to prevent saving the current index as a column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data = concat_data.reset_index(drop = True)\n",
    "print(concat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another method for combining data is  `merge( )`\n",
    "- First we'll read in the schools data again\n",
    "- And we'll read in the school indicator scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = pd.read_csv('../data/schools_clean.csv')\n",
    "schools.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = pd.read_csv('../data/school_indicator_scores_suppressed.csv')\n",
    "indicators.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we merge, we need to decide \n",
    "- which columns to keep from each dataframe  \n",
    "- what _type_ of merge we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's say we want to look at the effect of poverty on school indicators\n",
    "- From the schools data, we need name, total number of students, and total who are economically disadvantaged\n",
    "    - we need to create a column for the total number of students before we can subset the schools dataframe\n",
    "- From the school indicators dataframe, we need school name, and the six *score* columns\n",
    "    - filtering the dataframe first so that we only look at Davidson County schools is a good idea\n",
    "    - we also want to filter in order to keep only the rows where subgroup is \"All Students\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools['total_students'] = schools.male + schools.female\n",
    "schools.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_subset = schools[['name', 'total_students', 'econ_disadv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = indicators.loc[(indicators.system_name == 'Davidson County') & (indicators.subgroup == 'All Students')]\n",
    "indicators.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators_subset = indicators[['school_name', 'score_achievement', \n",
    "                                'score_growth', 'score_absenteeism',\n",
    "                                'score_grad', 'score_ready_grad', \n",
    "                                'score_elpa']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('schools subset: ', schools_subset.shape)\n",
    "print('indicators subset: ', indicators_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 12 more rows in the schools_subset data than there are in the indicators_subset\n",
    "- We want data that matches to **both** datasets \n",
    "![pandas merge types](../images/pandas_merge_types.png)\n",
    "- So we want an inner join (which is the default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_with_scores = pd.merge(schools_subset, indicators_subset, \n",
    "                               left_on = 'name', right_on = 'school_name', \n",
    "                               how = 'inner')\n",
    "schools_with_scores.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can drop one of the school name columns and calculate the percentage of students from each school who are economically disadvantaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_with_scores = schools_with_scores.drop(columns = 'school_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_with_scores['pct_econ_disadv'] = schools_with_scores.econ_disadv / schools_with_scores.total_students * 100\n",
    "schools_with_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll take a quick peak at the relationship between the percentage of students who are economically disadvantaged and the achievement score  for schools and then save this dataset for further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = 'score_achievement', y ='pct_econ_disadv', data = schools_with_scores)\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('percentage economically disadvantaged')\n",
    "plt.title('Score by percent economically disadvantaged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_with_scores.to_csv('../data/schools_with_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_csv('../data/schools_with_scores.csv')\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You want to plot the score distribution by zipcode for all zipcodes that have 10 or more schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First, slice the schools dataframe so you only have the 'name' and 'zipcode' columns.  Save this as zips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next, merge zips with_with_scores and name this dataframe test_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now use value_counts() to find which zipcode has the most schools.\n",
    "### (You can simply make a note, later in the course we learn how to automate this step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter the test_zips dataframe to include only that zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a barplot that shows the distribution of scores by school name for that zipcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
