{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pandas `.concat( )`  method is used to concatenate two dataframes based on shared column names\n",
    "- we will create two dataframes and then concatenate them\n",
    "- this would be useful if you had, for example, two different years of data with the same columns that you want to explore together; in a case like this, you would want to add a year column before joining them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = { 'Col1' : [1,2,3],\n",
    "         'Col2' : [4,5,6],\n",
    "         'Col3' : [7,8,9]}\n",
    "data2 = { 'Col1' : [4,5,6],\n",
    "         'Col2' : [7,8,9],\n",
    "         'Col3' : [1,2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = pd.DataFrame(data1)\n",
    "df_2019 = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('df_2018')\n",
    "print(df_2018)\n",
    "print('=================')\n",
    "print('df_2019')\n",
    "print(df_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before we concatenate `df_2018` and `df_2019` we need to add a column for the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018['year'] = '2018'\n",
    "df_2019['year'] = '2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data = pd.concat([df_2018, df_2019])\n",
    "concat_data\n",
    "\n",
    "## Notice that the index repeats itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `reset_index( )` method will change these to a 0-based incrementing index\n",
    "- add the `drop = True` argument to prevent saving the current index as a column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data = concat_data.reset_index(drop = True)\n",
    "print(concat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another method for combining data is  `merge( )`\n",
    "- First we'll read in the schools data again\n",
    "- And we'll read in the school indicator scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = pd.read_csv('../data/schools_clean.csv')\n",
    "schools.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = pd.read_csv('../data/school_indicator_scores_suppressed.csv')\n",
    "indicators.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we merge, we need to decide \n",
    "- which columns to keep from each dataframe  \n",
    "- what _type_ of merge we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's say we want to look at the effect of poverty on school indicators\n",
    "- From the schools data, we need name, total number of students, and total who are economically disadvantaged\n",
    "    - we need to create a column for the total number of students before we can subset the schools dataframe\n",
    "- From the school indicators dataframe, we need school name, and the six *score* columns\n",
    "    - filtering the dataframe first so that we only look at Davidson County schools is a good idea\n",
    "    - we also want to filter in order to keep only the rows where subgroup is \"All Students\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools['total_students'] = schools.male + schools.female\n",
    "schools.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_subset = schools[['name', 'total_students', 'econ_disadv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = indicators.loc[(indicators.system_name == 'Davidson County') & (indicators.subgroup == 'All Students')]\n",
    "indicators.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators_subset = indicators[['school_name', 'score_achievement', \n",
    "                                'score_growth', 'score_absenteeism',\n",
    "                                'score_grad', 'score_ready_grad', \n",
    "                                'score_elpa']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('schools subset: ', schools_subset.shape)\n",
    "print('indicators subset: ', indicators_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 12 more rows in the schools_subset data than there are in the indicators_subset\n",
    "- We want data that matches to **both** datasets \n",
    "![pandas merge types](../images/pandas_merge_types.png)\n",
    "- So we want an inner join (which is the default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_with_scores = pd.merge(schools_subset, indicators_subset, \n",
    "                               left_on = 'name', right_on = 'school_name', \n",
    "                               how = 'inner')\n",
    "schools_with_scores.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can drop one of the school name columns and calculate the percentage of students from each school who are economically disadvantaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_with_scores = schools_with_scores.drop(columns = 'school_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_with_scores['pct_econ_disadv'] = schools_with_scores.econ_disadv / schools_with_scores.total_students * 100\n",
    "schools_with_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll take a quick peak at the relationship between the percentage of students who are economically disadvantaged and the achievement score  for schools and then save this dataset for further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = 'score_achievement', y ='pct_econ_disadv', data = schools_with_scores)\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('percentage economically disadvantaged');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_with_scores.to_csv('../data/schools_with_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_csv('../data/schools_with_scores.csv')\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
